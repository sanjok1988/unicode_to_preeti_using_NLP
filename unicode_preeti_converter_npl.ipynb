{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z68tYuZ1x4J"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ASMUwF0s069x",
        "outputId": "19916c80-1545-42a5-d952-4bdf8417fdc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib\n",
            "  Downloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.0 (from torch)\n",
            "  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting setuptools>=40.8.0 (from triton==3.3.0->torch)\n",
            "  Downloading setuptools-80.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.31.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0 (from transformers)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from transformers)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tqdm>=4.27 (from transformers)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.2 (from pandas)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Downloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.58.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.5/104.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting pillow>=8 (from matplotlib)\n",
            "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting scipy>=1.6.0 (from scikit-learn)\n",
            "  Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
            "  Downloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m135.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m122.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.58.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.31.2-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.2/484.2 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.6/159.6 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.3/147.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.4.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytz, nvidia-cusparselt-cu12, mpmath, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, sympy, six, setuptools, safetensors, regex, pyyaml, pyparsing, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, kiwisolver, joblib, idna, fsspec, fonttools, filelock, cycler, charset-normalizer, certifi, triton, scipy, requests, python-dateutil, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, contourpy, scikit-learn, pandas, nvidia-cusolver-cu12, matplotlib, huggingface-hub, torch, tokenizers, transformers\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.6.0\n",
            "    Uninstalling threadpoolctl-3.6.0:\n",
            "      Successfully uninstalled threadpoolctl-3.6.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.5.3\n",
            "    Uninstalling safetensors-0.5.3:\n",
            "      Successfully uninstalled safetensors-0.5.3\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.3\n",
            "    Uninstalling pyparsing-3.2.3:\n",
            "      Successfully uninstalled pyparsing-3.2.3\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.8\n",
            "    Uninstalling kiwisolver-1.4.8:\n",
            "      Successfully uninstalled kiwisolver-1.4.8\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.5.0\n",
            "    Uninstalling joblib-1.5.0:\n",
            "      Successfully uninstalled joblib-1.5.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.57.0\n",
            "    Uninstalling fonttools-4.57.0:\n",
            "      Successfully uninstalled fonttools-4.57.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.2\n",
            "    Uninstalling charset-normalizer-3.4.2:\n",
            "      Successfully uninstalled charset-normalizer-3.4.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.4.26\n",
            "    Uninstalling certifi-2025.4.26:\n",
            "      Successfully uninstalled certifi-2025.4.26\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.2\n",
            "    Uninstalling contourpy-1.3.2:\n",
            "      Successfully uninstalled contourpy-1.3.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.31.1\n",
            "    Uninstalling huggingface-hub-0.31.1:\n",
            "      Successfully uninstalled huggingface-hub-0.31.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\n",
            "langchain-core 0.3.59 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 certifi-2025.4.26 charset-normalizer-3.4.2 contourpy-1.3.2 cycler-0.12.1 filelock-3.18.0 fonttools-4.58.0 fsspec-2025.3.2 huggingface-hub-0.31.2 idna-3.10 jinja2-3.1.6 joblib-1.5.0 kiwisolver-1.4.8 matplotlib-3.10.3 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.5 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 packaging-25.0 pandas-2.2.3 pillow-11.2.1 pyparsing-3.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.3 setuptools-80.4.0 six-1.17.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.21.1 torch-2.7.0 tqdm-4.67.1 transformers-4.51.3 triton-3.3.0 typing-extensions-4.13.2 tzdata-2025.2 urllib3-2.4.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "c953b92731134c81b370389bfdb891b2",
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "certifi",
                  "charset_normalizer",
                  "cycler",
                  "dateutil",
                  "huggingface_hub",
                  "joblib",
                  "kiwisolver",
                  "markupsafe",
                  "mpmath",
                  "pkg_resources",
                  "pytz",
                  "requests",
                  "setuptools",
                  "six",
                  "sympy",
                  "torch",
                  "torchgen",
                  "tqdm",
                  "transformers",
                  "triton",
                  "yaml"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install transformers pandas matplotlib scikit-learn --force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yeBRVH8Y6fIl",
        "outputId": "6d5d2a42-dbf1-45bb-dc12-46044715de2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.86)\n",
            "Collecting triton==3.3.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch) (80.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.2.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torch-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (955.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m955.6/955.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchvision-0.22.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, sympy, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sympy-1.13.3 torch-2.7.0+cu118 torchaudio-2.7.0+cu118 torchvision-0.22.0+cu118 triton-3.3.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "fd10b55841a24a89b072ec0c4d608792",
              "pip_warning": {
                "packages": [
                  "sympy",
                  "torch",
                  "torchgen",
                  "triton"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705,
          "referenced_widgets": [
            "d71023999f7a40f6ab6a07c0a3c226f7",
            "48ef0769a28d4507821e9ec4f2b35451",
            "0a559e5c51c743f7877e339153c336f9",
            "bc494639b9b34f258dde9a117f822b50",
            "865cb5d4c2854e35a7ab2a9aba61d4fa",
            "63eb540f3e51422996e5939dc3fc9bcb",
            "0a586419a5864262b1159a3fe1cb9e58",
            "cdb29b4759294d3d95a8a421254b558d",
            "7cd6efa9ed8049cb9137365901c69fca",
            "aff8adf2e3b1430aa560556104e71e82",
            "7ebd29fc5ea24a2498c633b9229ec07b",
            "385cd54dd493430baffe92d0fe42e2e7",
            "8d1f9d30649844908990003675a3ba80",
            "0f29aa89d1f445ff919564bfc7a7aafe",
            "60419b5fc1f34ab2ac7eb6df33379214",
            "ed93e798e8fb433596e56c301383f73d",
            "e85994e2fade45deb64960dac8af3fe8",
            "5ac9db94ca5f4a5bab02774db0a56680",
            "3427b890a0e746fdab1ee3faa4ec1f8b",
            "2fa38540576e44f4bd2793f721ac9fe5",
            "5bc0587c0bd94873808ac0ccb6df9ee1",
            "b4bb33642ba64a948df9bc6979a66166",
            "8c7fb31d3bf24991b42a85fd452bab4e",
            "224aa1bdd5ea4191b01bf5e4e30d3ee0",
            "272eda5afe184b579cdbb9fdd25165e5",
            "68f1c60b3adc43f185d75584376cf166",
            "c99bf143265046f684a4e8ae7c7538d9",
            "7b8dd83b096c4d9681d4e8777a108d43",
            "f912892bb1d7470c80f2ca23c0a69a9b",
            "dcd3a25c50d744a8b576d8a70c8fc710",
            "0c62f2eed2754edba73651d6b05b49c9",
            "ed4e05eedbe8488dad69cb02e5f27344",
            "bdaa8ba261bc412d9d19da9b38dd51b3"
          ]
        },
        "id": "GQ5BBU3v0qvz",
        "outputId": "3e4befea-c512-4d7a-d8f7-407e1d29996d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d71023999f7a40f6ab6a07c0a3c226f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "385cd54dd493430baffe92d0fe42e2e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 1/5 - Training:   0%|          | 0/2500 [00:00<?, ?it/s]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c7fb31d3bf24991b42a85fd452bab4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/312M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 - Training: 100%|██████████| 2500/2500 [08:26<00:00,  4.93it/s]\n",
            "Epoch 1/5 - Validation: 100%|██████████| 625/625 [00:39<00:00, 15.84it/s]\n",
            "Epoch 2/5 - Training: 100%|██████████| 2500/2500 [08:29<00:00,  4.90it/s]\n",
            "Epoch 2/5 - Validation: 100%|██████████| 625/625 [00:39<00:00, 15.89it/s]\n",
            "Epoch 3/5 - Training: 100%|██████████| 2500/2500 [08:29<00:00,  4.91it/s]\n",
            "Epoch 3/5 - Validation: 100%|██████████| 625/625 [00:39<00:00, 15.86it/s]\n",
            "Epoch 4/5 - Training: 100%|██████████| 2500/2500 [08:29<00:00,  4.91it/s]\n",
            "Epoch 4/5 - Validation: 100%|██████████| 625/625 [00:39<00:00, 16.00it/s]\n",
            "Epoch 5/5 - Training: 100%|██████████| 2500/2500 [08:29<00:00,  4.91it/s]\n",
            "Epoch 5/5 - Validation: 100%|██████████| 625/625 [00:39<00:00, 15.97it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[65000]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Inference Samples ---\n",
            "Unicode: गर्ने\n",
            "Preeti : ug]{\n",
            "\n",
            "Unicode: चीन जस्ता देशहरुले\n",
            "Preeti : rLg h:tf b]zx?n]\n",
            "\n",
            "Unicode: आदिलाई\n",
            "Preeti : cflbnfO{\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import logging\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Speed up\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Disable tokenizers parallelism warning\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "\n",
        "# Logging setup\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logger.info(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Dataset Class\n",
        "class UnicodePreetiFontDataset(Dataset):\n",
        "    def __init__(self, unicode_texts, preeti_texts, tokenizer, max_length=128):\n",
        "        self.unicode_texts = unicode_texts\n",
        "        self.preeti_texts = preeti_texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.unicode_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        unicode_text = str(self.unicode_texts[idx])\n",
        "        preeti_text = str(self.preeti_texts[idx])\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            unicode_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        target_encoding = self.tokenizer(\n",
        "            preeti_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'labels': target_encoding['input_ids'].squeeze()\n",
        "        }\n",
        "\n",
        "# Accuracy calculation\n",
        "def calculate_accuracy(preds, labels):\n",
        "    preds = preds.view(-1)\n",
        "    labels = labels.view(-1)\n",
        "    mask = labels != -100\n",
        "    correct = (preds[mask] == labels[mask]).sum().item()\n",
        "    total = mask.sum().item()\n",
        "    return correct / total if total > 0 else 0\n",
        "\n",
        "# Plotting function\n",
        "def plot_metrics(epochs, train_losses, val_losses, train_accuracies, val_accuracies):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label='Train Loss', color='blue')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss', color='red')\n",
        "    plt.title('Loss over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, label='Train Accuracy', color='green')\n",
        "    plt.plot(epochs, val_accuracies, label='Validation Accuracy', color='orange')\n",
        "    plt.title('Accuracy over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_metrics_plot.png')\n",
        "    plt.close()\n",
        "\n",
        "# Load CSV dataset\n",
        "def load_dataset(path, sample_fraction=1.0):\n",
        "    df = pd.read_csv(path, encoding='utf-8')\n",
        "    df = df.sample(frac=sample_fraction, random_state=42)\n",
        "\n",
        "    if 'unicode' not in df.columns or 'preeti' not in df.columns:\n",
        "        raise ValueError(\"CSV must contain 'unicode' and 'preeti' columns\")\n",
        "\n",
        "    return df['unicode'].tolist(), df['preeti'].tolist()\n",
        "\n",
        "# Model Training\n",
        "def train_model(unicode_texts, preeti_texts, model_name='facebook/nllb-200-distilled-600M', epochs=5):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "\n",
        "    train_texts, val_texts, train_labels, val_labels = train_test_split(unicode_texts, preeti_texts, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_dataset = UnicodePreetiFontDataset(train_texts, train_labels, tokenizer)\n",
        "    val_dataset = UnicodePreetiFontDataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=8)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=3e-5)\n",
        "    total_steps = len(train_loader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps)\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "    epoch_list = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = outputs.logits.argmax(dim=-1)\n",
        "            acc = calculate_accuracy(preds, labels)\n",
        "            total_acc += acc\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        avg_train_acc = total_acc / len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_acc = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Validation\"):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                val_loss += outputs.loss.item()\n",
        "\n",
        "                preds = outputs.logits.argmax(dim=-1)\n",
        "                val_acc += calculate_accuracy(preds, labels)\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        avg_val_acc = val_acc / len(val_loader)\n",
        "\n",
        "        logger.info(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Train Acc: {avg_train_acc:.4f} | Val Acc: {avg_val_acc:.4f}\")\n",
        "\n",
        "        epoch_list.append(epoch+1)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        train_accuracies.append(avg_train_acc)\n",
        "        val_accuracies.append(avg_val_acc)\n",
        "\n",
        "    plot_metrics(epoch_list, train_losses, val_losses, train_accuracies, val_accuracies)\n",
        "\n",
        "    model.save_pretrained(\"unicode_to_preeti_model\")\n",
        "    tokenizer.save_pretrained(\"unicode_to_preeti_model\")\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "# Inference\n",
        "def inference(text, model, tokenizer):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=128).to(device)\n",
        "    outputs = model.generate(inputs.input_ids, max_length=128, num_beams=4)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    unicode_texts, preeti_texts = load_dataset(\"/content/drive/MyDrive/thesis/phrase_dataset_unicode_to_preeti.csv\", sample_fraction=1.0)\n",
        "\n",
        "    model, tokenizer = train_model(unicode_texts, preeti_texts, epochs=5, model_name = \"Helsinki-NLP/opus-mt-en-ROMANCE\")\n",
        "\n",
        "    print(\"\\n--- Inference Samples ---\")\n",
        "    for i in range(3):\n",
        "        sample = unicode_texts[i]\n",
        "        result = inference(sample, model, tokenizer)\n",
        "        print(f\"Unicode: {sample}\")\n",
        "        print(f\"Preeti : {result}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Db15plL4LUZ8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import logging\n",
        "import pandas as pd\n",
        "\n",
        "# Logging setup\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logger.info(f\"Using device: {device}\")\n",
        "\n",
        "class UnicodePreetiFontConverter:\n",
        "    def __init__(self, model_path=\"/content/drive/MyDrive/thesis/unicode_to_preeti_model\"):\n",
        "        \"\"\"\n",
        "        Initialize the converter with pre-trained model\n",
        "\n",
        "        Args:\n",
        "            model_path (str): Path to saved model directory\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Load tokenizer and model\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "            self.model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(device)\n",
        "            self.model.eval()  # Set to evaluation mode\n",
        "\n",
        "            logger.info(\"Model loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Model loading error: {e}\")\n",
        "            raise\n",
        "\n",
        "    def convert_single(self, unicode_text, max_length=128):\n",
        "        \"\"\"\n",
        "        Convert single Unicode text to Preeti\n",
        "\n",
        "        Args:\n",
        "            unicode_text (str): Input Unicode text\n",
        "            max_length (int): Maximum length for tokenization\n",
        "\n",
        "        Returns:\n",
        "            str: Converted Preeti text\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Prepare input\n",
        "            inputs = self.tokenizer(\n",
        "                unicode_text,\n",
        "                return_tensors='pt',\n",
        "                truncation=True,\n",
        "                max_length=max_length\n",
        "            ).to(device)\n",
        "\n",
        "            # Generate translation\n",
        "            outputs = self.model.generate(\n",
        "                inputs.input_ids,\n",
        "                max_length=max_length,\n",
        "                num_beams=4,  # Beam search for better results\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "            # Decode output\n",
        "            preeti_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            return preeti_text\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Conversion error for text '{unicode_text}': {e}\")\n",
        "            return None\n",
        "\n",
        "    def batch_convert(self, unicode_texts, max_length=128):\n",
        "        \"\"\"\n",
        "        Convert multiple Unicode texts to Preeti\n",
        "\n",
        "        Args:\n",
        "            unicode_texts (list): List of Unicode texts\n",
        "            max_length (int): Maximum length for tokenization\n",
        "\n",
        "        Returns:\n",
        "            list: List of converted Preeti texts\n",
        "        \"\"\"\n",
        "        return [self.convert_single(text, max_length) for text in unicode_texts]\n",
        "\n",
        "    def convert_from_csv(self, csv_path, unicode_column='unicode', batch_size=32):\n",
        "        \"\"\"\n",
        "        Convert Unicode texts from CSV file\n",
        "\n",
        "        Args:\n",
        "            csv_path (str): Path to CSV file\n",
        "            unicode_column (str): Name of Unicode column\n",
        "            batch_size (int): Number of texts to process in each batch\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame with original and converted texts\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Read CSV\n",
        "            df = pd.read_csv(csv_path, encoding='utf-8')\n",
        "\n",
        "            if unicode_column not in df.columns:\n",
        "                raise ValueError(f\"Column '{unicode_column}' not found in CSV\")\n",
        "\n",
        "            # Convert texts in batches\n",
        "            converted_texts = []\n",
        "            for i in range(0, len(df), batch_size):\n",
        "                batch = df[unicode_column][i:i+batch_size].tolist()\n",
        "                converted_batch = self.batch_convert(batch)\n",
        "                converted_texts.extend(converted_batch)\n",
        "\n",
        "            # Add converted column\n",
        "            df['preeti_converted'] = converted_texts\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"CSV conversion error: {e}\")\n",
        "            return None\n",
        "\n",
        "def main():\n",
        "    # Initialize converter\n",
        "    converter = UnicodePreetiFontConverter()\n",
        "\n",
        "    # Single text conversion examples\n",
        "    print(\"\\n--- Single Text Conversion ---\")\n",
        "    test_texts = [\"क\", \"का\", \"कि\", \"की\"]\n",
        "    for text in test_texts:\n",
        "        preeti_text = converter.convert_single(text)\n",
        "        print(f\"Unicode: {text} | Preeti: {preeti_text}\")\n",
        "\n",
        "    # CSV conversion example\n",
        "    print(\"\\n--- CSV Batch Conversion ---\")\n",
        "    csv_path = 'sample_unicode_texts.csv'\n",
        "\n",
        "    # Ensure sample CSV exists\n",
        "    if not os.path.exists(csv_path):\n",
        "        sample_data = {\n",
        "            'unicode': ['क', 'का', 'कि', 'की', 'कु', 'के', 'अ', 'इ', 'उ'],\n",
        "            'description': ['Sample Nepali Character', 'ka', 'ki', 'kI', 'ku', 'ke', 'a', 'i', 'u']\n",
        "        }\n",
        "        pd.DataFrame(sample_data).to_csv(csv_path, index=False)\n",
        "        print(f\"Created sample CSV: {csv_path}\")\n",
        "\n",
        "    # Convert CSV\n",
        "    converted_df = converter.convert_from_csv(csv_path)\n",
        "    if converted_df is not None:\n",
        "        print(\"\\nConverted DataFrame:\")\n",
        "        print(converted_df)\n",
        "\n",
        "        # Optional: Save converted results\n",
        "        converted_df.to_csv('converted_unicode_to_preeti.csv', index=False)\n",
        "        print(\"Saved converted results to 'converted_unicode_to_preeti.csv'\")\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def display_preeti_text(text):\n",
        "    html = f\"\"\"\n",
        "    <style>\n",
        "    @font-face {{\n",
        "        font-family: 'Preeti';\n",
        "        src: url('Preeti.ttf') format('truetype');\n",
        "    }}\n",
        "    .preeti-text {{\n",
        "        font-family: 'Preeti';\n",
        "        font-size: 20px;\n",
        "    }}\n",
        "    </style>\n",
        "    preeti font:<div class=\"preeti-text\"> {text}</div></br>\n",
        "    \"\"\"\n",
        "    display(HTML(html))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "resources": {
            "http://localhost:8080/Preeti.ttf": {
              "data": "",
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "ok": false,
              "status": 404,
              "status_text": ""
            }
          }
        },
        "id": "lxK8nA4cR-dV",
        "outputId": "4c49f9e5-60e0-4d64-8c6f-2673c0313b63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Single Text Conversion ---\n",
            "Unicode: क | Preeti: s\n",
            "Unicode: का | Preeti: sf\n",
            "Unicode: कि | Preeti: ls\n",
            "Unicode: की | Preeti: sL\n",
            "\n",
            "--- CSV Batch Conversion ---\n",
            "Created sample CSV: sample_unicode_texts.csv\n",
            "\n",
            "Converted DataFrame:\n",
            "  unicode              description preeti_converted\n",
            "0       क  Sample Nepali Character                s\n",
            "1      का                       ka               sf\n",
            "2      कि                       ki               ls\n",
            "3      की                       kI               sL\n",
            "4      कु                       ku               s'\n",
            "5      के                       ke               s]\n",
            "6       अ                        a                c\n",
            "7       इ                        i                O\n",
            "8       उ                        u                p\n",
            "Saved converted results to 'converted_unicode_to_preeti.csv'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Advanced Text Processing ---\n",
            "Unicode: नमस्ते\n",
            "Preeti : gd:t]\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    @font-face {\n",
              "        font-family: 'Preeti';\n",
              "        src: url('Preeti.ttf') format('truetype');\n",
              "    }\n",
              "    .preeti-text {\n",
              "        font-family: 'Preeti';\n",
              "        font-size: 20px;\n",
              "    }\n",
              "    </style>\n",
              "    preeti font:<div class=\"preeti-text\"> gd:t]</div></br>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unicode: डाटा विज्ञान\n",
            "Preeti : 8f6f lj1fg\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    @font-face {\n",
              "        font-family: 'Preeti';\n",
              "        src: url('Preeti.ttf') format('truetype');\n",
              "    }\n",
              "    .preeti-text {\n",
              "        font-family: 'Preeti';\n",
              "        font-size: 20px;\n",
              "    }\n",
              "    </style>\n",
              "    preeti font:<div class=\"preeti-text\"> 8f6f lj1fg</div></br>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unicode: कम्प्युटर\n",
            "Preeti : sDKo'6/\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    @font-face {\n",
              "        font-family: 'Preeti';\n",
              "        src: url('Preeti.ttf') format('truetype');\n",
              "    }\n",
              "    .preeti-text {\n",
              "        font-family: 'Preeti';\n",
              "        font-size: 20px;\n",
              "    }\n",
              "    </style>\n",
              "    preeti font:<div class=\"preeti-text\"> sDKo'6/</div></br>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unicode: मेराे नाम सुमन हाे । what is yours?\n",
            "Preeti : d]/f] gfd ;'dg xf] wf]\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    @font-face {\n",
              "        font-family: 'Preeti';\n",
              "        src: url('Preeti.ttf') format('truetype');\n",
              "    }\n",
              "    .preeti-text {\n",
              "        font-family: 'Preeti';\n",
              "        font-size: 20px;\n",
              "    }\n",
              "    </style>\n",
              "    preeti font:<div class=\"preeti-text\"> d]/f] gfd ;'dg xf] wf]</div></br>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unicode: मेराे नाम पुजन हाे ।  तिमी के गछाै \n",
            "Preeti : d]/f] gfd k'hg xf] wf] ltdL s] u5f}\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    @font-face {\n",
              "        font-family: 'Preeti';\n",
              "        src: url('Preeti.ttf') format('truetype');\n",
              "    }\n",
              "    .preeti-text {\n",
              "        font-family: 'Preeti';\n",
              "        font-size: 20px;\n",
              "    }\n",
              "    </style>\n",
              "    preeti font:<div class=\"preeti-text\"> d]/f] gfd k'hg xf] wf] ltdL s] u5f}</div></br>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unicode: गाराे छ केटा हाे । स्यालरी कहिले अाउने हाे \n",
            "Preeti : uf/f] 5 s]6f xf] wf] ;ofn/L slxn] cfpg] xf]\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    @font-face {\n",
              "        font-family: 'Preeti';\n",
              "        src: url('Preeti.ttf') format('truetype');\n",
              "    }\n",
              "    .preeti-text {\n",
              "        font-family: 'Preeti';\n",
              "        font-size: 20px;\n",
              "    }\n",
              "    </style>\n",
              "    preeti font:<div class=\"preeti-text\"> uf/f] 5 s]6f xf] wf] ;ofn/L slxn] cfpg] xf]</div></br>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def advanced_text_processing_demo():\n",
        "    \"\"\"\n",
        "    Advanced text processing demonstration\n",
        "    \"\"\"\n",
        "    converter = UnicodePreetiFontConverter()\n",
        "\n",
        "    # Complex text processing scenarios\n",
        "    complex_texts = [\n",
        "        \"नमस्ते\",  # Greeting\n",
        "        \"डाटा विज्ञान\",  # Data Science\n",
        "        \"कम्प्युटर\",  # Computer\n",
        "        \"मेराे नाम सुमन हाे । what is yours?\",\n",
        "        \"मेराे नाम पुजन हाे ।  तिमी के गछाै \",\n",
        "        \"गाराे छ केटा हाे । स्यालरी कहिले अाउने हाे \"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Advanced Text Processing ---\")\n",
        "    for text in complex_texts:\n",
        "        preeti_text = converter.convert_single(text)\n",
        "        print(f\"Unicode: {text}\")\n",
        "        print(f\"Preeti : {preeti_text}\\n\")\n",
        "        predicted_text = display_preeti_text(preeti_text)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    advanced_text_processing_demo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "--YdyjAjjWl4"
      },
      "outputs": [],
      "source": [
        "def test_converter_metrics():\n",
        "    \"\"\"\n",
        "    Test the converter using CER (Character Error Rate) and BLEU score metrics\n",
        "    \"\"\"\n",
        "    import nltk\n",
        "    from nltk.translate.bleu_score import sentence_bleu\n",
        "    nltk.download('punkt')\n",
        "\n",
        "    # Initialize converter\n",
        "    converter = UnicodePreetiFontConverter()\n",
        "\n",
        "    # Load test dataset with known ground truth\n",
        "    test_data = [\n",
        "        {\"unicode\": \"क\", \"expected_preeti\": \"s\"},\n",
        "        {\"unicode\": \"का\", \"expected_preeti\": \"sf\"},\n",
        "        {\"unicode\": \"कि\", \"expected_preeti\": \"ls\"},\n",
        "        {\"unicode\": \"नमस्ते\", \"expected_preeti\": \"gd:t]\"}\n",
        "    ]\n",
        "\n",
        "    # Calculate metrics\n",
        "    cer_total = 0\n",
        "    bleu_scores = []\n",
        "\n",
        "    print(\"\\n--- CER/BLEU Evaluation ---\")\n",
        "    print(f\"{'Unicode':<15} {'Expected':<15} {'Predicted':<15} {'CER':<10} {'BLEU':<10}\")\n",
        "    print(\"-\" * 65)\n",
        "\n",
        "    for item in test_data:\n",
        "        unicode_text = item[\"unicode\"]\n",
        "        expected = item[\"expected_preeti\"]\n",
        "        predicted = converter.convert_single(unicode_text)\n",
        "\n",
        "        # Calculate Character Error Rate (CER)\n",
        "        edit_distance = nltk.edit_distance(predicted, expected)\n",
        "        cer = edit_distance / max(len(expected), 1)\n",
        "        cer_total += cer\n",
        "\n",
        "        # Calculate BLEU score\n",
        "        reference = [list(expected)]\n",
        "        candidate = list(predicted)\n",
        "        bleu = sentence_bleu(reference, candidate)\n",
        "        bleu_scores.append(bleu)\n",
        "\n",
        "        print(f\"{unicode_text:<15} {expected:<15} {predicted:<15} {cer:.4f}      {bleu:.4f}\")\n",
        "\n",
        "    # Calculate average metrics\n",
        "    avg_cer = cer_total / len(test_data)\n",
        "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "\n",
        "    print(\"-\" * 65)\n",
        "    print(f\"Average CER: {avg_cer:.4f} (lower is better)\")\n",
        "    print(f\"Average BLEU: {avg_bleu:.4f} (higher is better)\")\n",
        "\n",
        "    return avg_cer, avg_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7jkSbYy_jYrv"
      },
      "outputs": [],
      "source": [
        "def test_qualitative_assessment():\n",
        "    \"\"\"\n",
        "    Perform qualitative assessment of the converter\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    from matplotlib.font_manager import FontProperties\n",
        "\n",
        "    # Initialize converter\n",
        "    converter = UnicodePreetiFontConverter()\n",
        "\n",
        "    # Sample texts of varying complexity\n",
        "    test_samples = [\n",
        "        {\"category\": \"Simple\", \"texts\": [\"क\", \"ख\", \"ग\", \"घ\"]},\n",
        "        {\"category\": \"Medium\", \"texts\": [\"नमस्ते\", \"कस्तो छ\", \"धन्यवाद\"]},\n",
        "        {\"category\": \"Complex\", \"texts\": [\"नेपाली भाषा\", \"कम्प्युटर विज्ञान\", \"प्रविधि र विकास\"]}\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Qualitative Assessment ---\")\n",
        "\n",
        "    # Process each category\n",
        "    for category in test_samples:\n",
        "        print(f\"\\nCategory: {category['category']}\")\n",
        "        print(f\"{'Unicode':<20} {'Preeti':<20}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        for text in category[\"texts\"]:\n",
        "            converted = converter.convert_single(text)\n",
        "            print(f\"{text:<20} {converted:<20}\")\n",
        "\n",
        "    # Visual comparison of sample texts\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.subplot(1, 1, 1)\n",
        "    plt.title(\"Qualitative Assessment Results\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    y_position = 0.95\n",
        "    plt.text(0.1, y_position, \"Unicode\", fontsize=14, fontweight='bold')\n",
        "    plt.text(0.5, y_position, \"Preeti (Converted)\", fontsize=14, fontweight='bold')\n",
        "    y_position -= 0.05\n",
        "\n",
        "    # Add samples to plot\n",
        "    for i, category in enumerate(test_samples):\n",
        "        y_position -= 0.05\n",
        "        plt.text(0.02, y_position, f\"{category['category']}:\", fontsize=12, fontweight='bold')\n",
        "        y_position -= 0.03\n",
        "\n",
        "        for text in category[\"texts\"]:\n",
        "            converted = converter.convert_single(text)\n",
        "            plt.text(0.1, y_position, text, fontsize=11)\n",
        "            plt.text(0.5, y_position, converted, fontsize=11)\n",
        "            y_position -= 0.03\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('qualitative_assessment.png')\n",
        "    plt.close()\n",
        "    print(\"\\nQualitative assessment visualization saved as 'qualitative_assessment.png'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xIvsxA4Qje3N"
      },
      "outputs": [],
      "source": [
        "def test_performance_benchmark():\n",
        "    \"\"\"\n",
        "    Benchmark the performance of the converter\n",
        "    \"\"\"\n",
        "    import time\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Initialize converter\n",
        "    converter = UnicodePreetiFontConverter()\n",
        "\n",
        "    # Test different input lengths\n",
        "    test_cases = [\n",
        "        {\"type\": \"Single Character\", \"text\": \"क\"},\n",
        "        {\"type\": \"Word\", \"text\": \"नेपाली\"},\n",
        "        {\"type\": \"Short Sentence\", \"text\": \"नमस्ते। कस्तो छ?\"},\n",
        "        {\"type\": \"Medium Sentence\", \"text\": \"आज नेपालमा धेरै मानिसहरू छन्।\"},\n",
        "        {\"type\": \"Long Sentence\", \"text\": \"नेपाल एक सुन्दर देश हो जहाँ विभिन्न संस्कृति, भाषा र परम्परा पाइन्छ। यहाँको प्राकृतिक सौन्दर्य संसारभरि प्रसिद्ध छ।\"}\n",
        "    ]\n",
        "\n",
        "    # Record processing times\n",
        "    processing_times = []\n",
        "    text_lengths = []\n",
        "    text_types = []\n",
        "\n",
        "    print(\"\\n--- Performance Benchmark ---\")\n",
        "    print(f\"{'Type':<20} {'Length':<10} {'Time (ms)':<15}\")\n",
        "    print(\"-\" * 45)\n",
        "\n",
        "    for case in test_cases:\n",
        "        text_type = case[\"type\"]\n",
        "        text = case[\"text\"]\n",
        "        text_length = len(text)\n",
        "\n",
        "        # Measure performance (average of 5 runs)\n",
        "        times = []\n",
        "        for _ in range(5):\n",
        "            start_time = time.time()\n",
        "            _ = converter.convert_single(text)\n",
        "            end_time = time.time()\n",
        "            times.append((end_time - start_time) * 1000)  # convert to ms\n",
        "\n",
        "        avg_time = np.mean(times)\n",
        "\n",
        "        print(f\"{text_type:<20} {text_length:<10} {avg_time:.2f}\")\n",
        "\n",
        "        text_types.append(text_type)\n",
        "        text_lengths.append(text_length)\n",
        "        processing_times.append(avg_time)\n",
        "\n",
        "    # Create performance visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    bars = plt.bar(text_types, processing_times, color='skyblue')\n",
        "\n",
        "    # Add text lengths on top of bars\n",
        "    for i, bar in enumerate(bars):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
        "                f'{text_lengths[i]} chars', ha='center', fontsize=9)\n",
        "\n",
        "    plt.title('Conversion Performance by Text Type')\n",
        "    plt.xlabel('Text Type')\n",
        "    plt.ylabel('Processing Time (ms)')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('performance_benchmark.png')\n",
        "    plt.close()\n",
        "\n",
        "    print(\"\\nPerformance benchmark visualization saved as 'performance_benchmark.png'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csDv9MPnjiBM",
        "outputId": "74695e22-e3cb-4aa2-db62-12dbb45cf9e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========== UNICODE TO PREETI CONVERTER TESTING ==========\n",
            "\n",
            "[TEST 1] CER/BLEU Metrics Evaluation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- CER/BLEU Evaluation ---\n",
            "Unicode         Expected        Predicted       CER        BLEU      \n",
            "-----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "क               s               s               0.0000      0.0000\n",
            "का              sf              sf              0.0000      0.0000\n",
            "कि              ls              ls              0.0000      0.0000\n",
            "नमस्ते          gd:t]           gd:t]           0.0000      1.0000\n",
            "-----------------------------------------------------------------\n",
            "Average CER: 0.0000 (lower is better)\n",
            "Average BLEU: 0.2500 (higher is better)\n",
            "\n",
            "[TEST 2] Qualitative Assessment\n",
            "\n",
            "--- Qualitative Assessment ---\n",
            "\n",
            "Category: Simple\n",
            "Unicode              Preeti              \n",
            "----------------------------------------\n",
            "क                    s                   \n",
            "ख                    v                   \n",
            "ग                    u                   \n",
            "घ                    3                   \n",
            "\n",
            "Category: Medium\n",
            "Unicode              Preeti              \n",
            "----------------------------------------\n",
            "नमस्ते               gd:t]               \n",
            "कस्तो छ              s:tf] 5             \n",
            "धन्यवाद              wGojfb              \n",
            "\n",
            "Category: Complex\n",
            "Unicode              Preeti              \n",
            "----------------------------------------\n",
            "नेपाली भाषा          g]kfnL efif         \n",
            "कम्प्युटर विज्ञान    sDKo'6/ lj1fg       \n",
            "प्रविधि र विकास      kljlw / ljsf;       \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2328 (\\N{DEVANAGARI LETTER GHA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2350 (\\N{DEVANAGARI LETTER MA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2360 (\\N{DEVANAGARI LETTER SA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2381 (\\N{DEVANAGARI SIGN VIRAMA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2375 (\\N{DEVANAGARI VOWEL SIGN E}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2331 (\\N{DEVANAGARI LETTER CHA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2343 (\\N{DEVANAGARI LETTER DHA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2351 (\\N{DEVANAGARI LETTER YA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2357 (\\N{DEVANAGARI LETTER VA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2342 (\\N{DEVANAGARI LETTER DA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2346 (\\N{DEVANAGARI LETTER PA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2354 (\\N{DEVANAGARI LETTER LA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2368 (\\N{DEVANAGARI VOWEL SIGN II}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2349 (\\N{DEVANAGARI LETTER BHA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2359 (\\N{DEVANAGARI LETTER SSA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2369 (\\N{DEVANAGARI VOWEL SIGN U}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2335 (\\N{DEVANAGARI LETTER TTA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2332 (\\N{DEVANAGARI LETTER JA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:53: UserWarning: Glyph 2334 (\\N{DEVANAGARI LETTER NYA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2328 (\\N{DEVANAGARI LETTER GHA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2350 (\\N{DEVANAGARI LETTER MA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2360 (\\N{DEVANAGARI LETTER SA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2381 (\\N{DEVANAGARI SIGN VIRAMA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2375 (\\N{DEVANAGARI VOWEL SIGN E}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2331 (\\N{DEVANAGARI LETTER CHA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2343 (\\N{DEVANAGARI LETTER DHA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2351 (\\N{DEVANAGARI LETTER YA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2357 (\\N{DEVANAGARI LETTER VA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2342 (\\N{DEVANAGARI LETTER DA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2346 (\\N{DEVANAGARI LETTER PA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2354 (\\N{DEVANAGARI LETTER LA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2368 (\\N{DEVANAGARI VOWEL SIGN II}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2349 (\\N{DEVANAGARI LETTER BHA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2359 (\\N{DEVANAGARI LETTER SSA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2369 (\\N{DEVANAGARI VOWEL SIGN U}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2335 (\\N{DEVANAGARI LETTER TTA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2332 (\\N{DEVANAGARI LETTER JA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n",
            "<ipython-input-10-cff367787a41>:54: UserWarning: Glyph 2334 (\\N{DEVANAGARI LETTER NYA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('qualitative_assessment.png')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Qualitative assessment visualization saved as 'qualitative_assessment.png'\n",
            "\n",
            "[TEST 3] Performance Benchmark\n",
            "\n",
            "--- Performance Benchmark ---\n",
            "Type                 Length     Time (ms)      \n",
            "---------------------------------------------\n",
            "Single Character     1          184.88\n",
            "Word                 6          386.03\n",
            "Short Sentence       16         820.61\n",
            "Medium Sentence      29         1503.17\n",
            "Long Sentence        115        4853.59\n",
            "\n",
            "Performance benchmark visualization saved as 'performance_benchmark.png'\n",
            "\n",
            "Test summary visualization saved as 'test_summary.png'\n",
            "\n",
            "========== TESTING COMPLETED ==========\n"
          ]
        }
      ],
      "source": [
        "def run_comprehensive_tests():\n",
        "    \"\"\"\n",
        "    Run all tests in a comprehensive test suite\n",
        "    \"\"\"\n",
        "    print(\"\\n========== UNICODE TO PREETI CONVERTER TESTING ==========\")\n",
        "\n",
        "    # Test 1: Metrics Evaluation\n",
        "    print(\"\\n[TEST 1] CER/BLEU Metrics Evaluation\")\n",
        "    cer, bleu = test_converter_metrics()\n",
        "\n",
        "    # Test 2: Qualitative Assessment\n",
        "    print(\"\\n[TEST 2] Qualitative Assessment\")\n",
        "    test_qualitative_assessment()\n",
        "\n",
        "    # Test 3: Performance Benchmark\n",
        "    print(\"\\n[TEST 3] Performance Benchmark\")\n",
        "    test_performance_benchmark()\n",
        "\n",
        "    # Generate visual analysis with image\n",
        "    generate_test_summary(cer, bleu)\n",
        "\n",
        "    print(\"\\n========== TESTING COMPLETED ==========\")\n",
        "\n",
        "def generate_test_summary(cer, bleu):\n",
        "    \"\"\"\n",
        "    Generate and visualize a summary of all test results\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Create a visual summary of test results\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Title\n",
        "    plt.suptitle(\"Unicode to Preeti Converter - Test Results Summary\", fontsize=16, y=0.98)\n",
        "\n",
        "    # Metrics Results\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.bar(['CER', 'BLEU'], [cer, bleu], color=['red', 'green'])\n",
        "    plt.title('Metrics Evaluation')\n",
        "    plt.ylim(0, 1)\n",
        "\n",
        "    # Add text display of metrics\n",
        "    plt.text(0, cer + 0.05, f'{cer:.4f}', ha='center')\n",
        "    plt.text(1, bleu + 0.05, f'{bleu:.4f}', ha='center')\n",
        "\n",
        "    # Add note about metric interpretation\n",
        "    plt.figtext(0.25, 0.4, \"CER: Lower is better\\nBLEU: Higher is better\",\n",
        "                bbox=dict(facecolor='yellow', alpha=0.2))\n",
        "\n",
        "    # Add placeholder for qualitative results\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.axis('off')\n",
        "    plt.title('Qualitative Assessment')\n",
        "    plt.text(0.5, 0.5, \"See 'qualitative_assessment.png'\\nfor detailed results\",\n",
        "             ha='center', va='center', fontsize=10,\n",
        "             bbox=dict(facecolor='lightblue', alpha=0.4))\n",
        "\n",
        "    # Add placeholder for performance results\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.axis('off')\n",
        "    plt.title('Performance Benchmark')\n",
        "    plt.text(0.5, 0.5, \"See 'performance_benchmark.png'\\nfor detailed results\",\n",
        "             ha='center', va='center', fontsize=10,\n",
        "             bbox=dict(facecolor='lightgreen', alpha=0.4))\n",
        "\n",
        "    # Add recommendations based on test results\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.axis('off')\n",
        "    plt.title('Recommendations')\n",
        "\n",
        "    # Generate recommendations based on metrics\n",
        "    recommendations = []\n",
        "    if cer < 0.2:\n",
        "        recommendations.append(\"✓ CER is good (<0.2)\")\n",
        "    else:\n",
        "        recommendations.append(\"✗ CER needs improvement (>0.2)\")\n",
        "\n",
        "    if bleu > 0.7:\n",
        "        recommendations.append(\"✓ BLEU score is good (>0.7)\")\n",
        "    else:\n",
        "        recommendations.append(\"✗ BLEU score needs improvement (<0.7)\")\n",
        "\n",
        "    recommendations.append(\"➤ See detailed reports for more insights\")\n",
        "\n",
        "    # Display recommendations\n",
        "    y_pos = 0.8\n",
        "    for rec in recommendations:\n",
        "        plt.text(0.1, y_pos, rec, fontsize=10)\n",
        "        y_pos -= 0.2\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.savefig('test_summary.png')\n",
        "    plt.close()\n",
        "\n",
        "    print(\"\\nTest summary visualization saved as 'test_summary.png'\")\n",
        "\n",
        "# Run all tests\n",
        "if __name__ == \"__main__\":\n",
        "    run_comprehensive_tests()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a559e5c51c743f7877e339153c336f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdb29b4759294d3d95a8a421254b558d",
            "max": 312087009,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7cd6efa9ed8049cb9137365901c69fca",
            "value": 312087009
          }
        },
        "0a586419a5864262b1159a3fe1cb9e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c62f2eed2754edba73651d6b05b49c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f29aa89d1f445ff919564bfc7a7aafe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3427b890a0e746fdab1ee3faa4ec1f8b",
            "max": 293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fa38540576e44f4bd2793f721ac9fe5",
            "value": 293
          }
        },
        "224aa1bdd5ea4191b01bf5e4e30d3ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b8dd83b096c4d9681d4e8777a108d43",
            "placeholder": "​",
            "style": "IPY_MODEL_f912892bb1d7470c80f2ca23c0a69a9b",
            "value": "model.safetensors: 100%"
          }
        },
        "272eda5afe184b579cdbb9fdd25165e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd3a25c50d744a8b576d8a70c8fc710",
            "max": 312062580,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c62f2eed2754edba73651d6b05b49c9",
            "value": 312062580
          }
        },
        "2fa38540576e44f4bd2793f721ac9fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3427b890a0e746fdab1ee3faa4ec1f8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "385cd54dd493430baffe92d0fe42e2e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d1f9d30649844908990003675a3ba80",
              "IPY_MODEL_0f29aa89d1f445ff919564bfc7a7aafe",
              "IPY_MODEL_60419b5fc1f34ab2ac7eb6df33379214"
            ],
            "layout": "IPY_MODEL_ed93e798e8fb433596e56c301383f73d"
          }
        },
        "48ef0769a28d4507821e9ec4f2b35451": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63eb540f3e51422996e5939dc3fc9bcb",
            "placeholder": "​",
            "style": "IPY_MODEL_0a586419a5864262b1159a3fe1cb9e58",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "5ac9db94ca5f4a5bab02774db0a56680": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bc0587c0bd94873808ac0ccb6df9ee1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60419b5fc1f34ab2ac7eb6df33379214": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bc0587c0bd94873808ac0ccb6df9ee1",
            "placeholder": "​",
            "style": "IPY_MODEL_b4bb33642ba64a948df9bc6979a66166",
            "value": " 293/293 [00:00&lt;00:00, 30.9kB/s]"
          }
        },
        "63eb540f3e51422996e5939dc3fc9bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68f1c60b3adc43f185d75584376cf166": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed4e05eedbe8488dad69cb02e5f27344",
            "placeholder": "​",
            "style": "IPY_MODEL_bdaa8ba261bc412d9d19da9b38dd51b3",
            "value": " 312M/312M [00:02&lt;00:00, 148MB/s]"
          }
        },
        "7b8dd83b096c4d9681d4e8777a108d43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cd6efa9ed8049cb9137365901c69fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ebd29fc5ea24a2498c633b9229ec07b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "865cb5d4c2854e35a7ab2a9aba61d4fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c7fb31d3bf24991b42a85fd452bab4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_224aa1bdd5ea4191b01bf5e4e30d3ee0",
              "IPY_MODEL_272eda5afe184b579cdbb9fdd25165e5",
              "IPY_MODEL_68f1c60b3adc43f185d75584376cf166"
            ],
            "layout": "IPY_MODEL_c99bf143265046f684a4e8ae7c7538d9"
          }
        },
        "8d1f9d30649844908990003675a3ba80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e85994e2fade45deb64960dac8af3fe8",
            "placeholder": "​",
            "style": "IPY_MODEL_5ac9db94ca5f4a5bab02774db0a56680",
            "value": "generation_config.json: 100%"
          }
        },
        "aff8adf2e3b1430aa560556104e71e82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4bb33642ba64a948df9bc6979a66166": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc494639b9b34f258dde9a117f822b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aff8adf2e3b1430aa560556104e71e82",
            "placeholder": "​",
            "style": "IPY_MODEL_7ebd29fc5ea24a2498c633b9229ec07b",
            "value": " 312M/312M [00:02&lt;00:00, 267MB/s]"
          }
        },
        "bdaa8ba261bc412d9d19da9b38dd51b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c99bf143265046f684a4e8ae7c7538d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdb29b4759294d3d95a8a421254b558d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d71023999f7a40f6ab6a07c0a3c226f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48ef0769a28d4507821e9ec4f2b35451",
              "IPY_MODEL_0a559e5c51c743f7877e339153c336f9",
              "IPY_MODEL_bc494639b9b34f258dde9a117f822b50"
            ],
            "layout": "IPY_MODEL_865cb5d4c2854e35a7ab2a9aba61d4fa"
          }
        },
        "dcd3a25c50d744a8b576d8a70c8fc710": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e85994e2fade45deb64960dac8af3fe8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed4e05eedbe8488dad69cb02e5f27344": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed93e798e8fb433596e56c301383f73d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f912892bb1d7470c80f2ca23c0a69a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
